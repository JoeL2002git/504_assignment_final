# Remote Patient Monitoring (RPM) Pipeline for Hypertension Management: Use Case Description

## Problem Statement

Many patients with hypertension experience poor blood pressure control between office visits, contributing to preventable complications including emergency department utilization, stroke, and heart failure exacerbations. Currently, clinicians rely on infrequent office readings documented in the electronic health record (EHR), which fail to capture day-to-day variability, medication adherence patterns, or early warning signs of decompensation. The proposed remote patient monitoring mini-pipeline addresses this gap by enabling continuous collection of home blood pressure readings and related vital signs, automatically identifying out-of-range trends and low-adherence patients, and presenting actionable daily worklists to the clinic care team for timely clinical interventions.

The primary users include nurse care managers who monitor daily alerts and perform phone or text outreach to adjust care plans per protocol; primary care physicians who review summarized trends before patient visits and approve medication changes; and enrolled hypertensive patients who use home devices, receive automated reminders and educational messages, and communicate with the care team through a patient portal or secure messaging system. Secondary stakeholders include clinic operations leaders who track program metrics such as enrollment counts, alert volumes, and blood pressure control rates to inform staffing and resource allocation decisions.

## Data Sources

The pipeline ingests a realistic set of structured clinical and device data from multiple upstream systems. Device and vital sign data form the primary feed, consisting of blood pressure readings (systolic and diastolic), heart rate, and optional weight measurements from Bluetooth-enabled cuffs and scales. These readings arrive as JSON payloads from the RPM vendor's cloud platform or integration service, with each message containing patient identifiers, device metadata, timestamps, and measurement values. Patient and enrollment data are sourced nightly from EHR exports in CSV or FHIR format, including demographics, primary care provider attribution, ICD-10 diagnosis codes (e.g., hypertension), contact information, program enrollment start and end dates, consent status, and assigned device type. The pipeline also incorporates reference and configuration data maintained in relational tables or YAML configuration files, such as alert thresholds (e.g., systolic > 160 on two of the last three readings) and adherence rules (e.g., minimum 16 days of readings per month for billing qualification). Finally, derived analytics tables containing aggregated daily patient metrics, program performance summaries, and patient-level trend indicators feed the downstream dashboards and clinician-facing interfaces.

## Basic Workflow

1. The workflow begins with device data capture and ingestion, where patients measure blood pressure and vitals on assigned Bluetooth devices at home; data flows via a mobile app or cellular hub to the RPM vendor platform, which exposes an API or webhook to push new readings as JSON messages into the clinic's cloud ingestion layer (e.g., Azure Function or Logic App writing to blob storage). Raw payloads are landed with minimal transformation into a dedicated container or table, preserving original timestamps and device metadata. A scheduled validation job then checks for missing fields, impossible values (e.g., systolic < 60 or > 260), and duplicate readings, writing clean records to a validated_vitals table and logging errors for manual review.

2. Nightly EHR exports synchronize patient demographics, PCP attribution, and active RPM enrollment statuses into the data platform via CSV or FHIR-based ETL jobs, with a master patient index ensuring that device readings link to the correct patient using a stable shared identifier. A transformation job (scheduled notebook or data factory pipeline) subsequently joins validated vitals with patient and enrollment tables to produce a patient_daily_metrics table, calculating daily mean, minimum, and maximum systolic and diastolic pressure, reading counts, days since last reading, adherence flags, and alert flags based on configurable rules. A rules engine or SQL logic then writes new or updated alert records to an rpm_alerts table whenever a patient crosses a threshold or remains uncontrolled over time.

3. Clinician and patient-facing interfaces consume these alerts and metrics through a lightweight API or direct business intelligence connection. Nurse care managers access a daily worklist dashboard sorted by alert severity with drill-down patient pages showing seven-, thirty-, and ninety-day trend charts, adherence history, and clinical notes. Clinicians can document interventions (e.g., medication titration, education call) within or alongside the EHR and trigger secure messages or portal notifications to patients. Finally, aggregated tables feed a program monitoring dashboard for clinic leadership tracking enrollment counts, percentage of patients at blood pressure goal over time, alert volumes, average response times, and RPM-related visit and emergency department utilization trends. This reporting layer supports quality improvement and financial impact evaluation, while a feedback loop allows clinical and operational teams to iteratively refine alert rules and patient selection criteria through versioned configuration updates, ensuring the pipeline evolves to meet changing clinical needs.
